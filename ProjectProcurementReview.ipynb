{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4329b8b7-d7a7-449b-81b7-af351449627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\endij\\OneDrive\\Dokumenti\\Justine\\vpp-cfla\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Line magic functions that will allow for imports to be reloaded and not cached\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from datetime import date\n",
    "\n",
    "# Local\n",
    "from scripts.extractmd import Extractor\n",
    "from scripts.vectorindex import QnAEngine\n",
    "from scripts.utilities import get_prompt_dict, get_questions, get_answers, get_procurement_content, get_config_data\n",
    "from scripts.gen_results import gen_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f04cb-807c-48b2-b474-8b97dbb0a6d5",
   "metadata": {},
   "source": [
    "**Global config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a282ce0b-1aba-417c-bf9a-15cbe840c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_conf = {\n",
    "    \"embeddingmodel\": \"BAAI/bge-m3\",  # \"BAAI/bge-m3\" \"nomic-ai/nomic-embed-text-v2-moe\" # \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
    "    \"chunk_size\": 1536,\n",
    "    \"chunk_overlap\": 0,\n",
    "    \"top_similar\": 5,\n",
    "    \"n4rerank\": 20, #How many nodes to retrieve for reranking. If 0, reranker is not used\n",
    "    \"use_similar_chunks\": True, #To use similar chunks or the whole document as the context\n",
    "    \"prevnext\": True #to include in the context also the previouse and the next chunk of the current similar chunk\n",
    "}\n",
    "embedding=HuggingFaceEmbedding(model_name=embedding_conf[\"embeddingmodel\"],trust_remote_code=True)\n",
    "\n",
    "#For nomic-embed-text-v2-moe\n",
    "#embedding=HuggingFaceEmbedding(model_name=embedding_conf[\"embeddingmodel\"],trust_remote_code=True,query_instruction=\"search_query: \",text_instruction=\"search_document: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e114f1-c05e-48b1-b56a-051ece6102eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Setup \n",
    "llmmodelAzure = { \"model\": \"gpt-4o\",\n",
    "                \"version\":os.environ.get('AZURE_OPENAI_VERSION',''),\n",
    "                \"azure_deployment\":\"gpt-4o\",\n",
    "                \"azure_endpoint\":os.environ.get('AZURE_ENDPOINT',''),\n",
    "                \"api_key\":os.environ.get('AZURE_OPENAI_KEY','')}\n",
    "\n",
    "llm=AzureOpenAI(azure_deployment=llmmodelAzure[\"azure_deployment\"],\n",
    "                azure_endpoint=llmmodelAzure[\"azure_endpoint\"],temperature=0.0,\n",
    "                api_version=llmmodelAzure[\"version\"], api_key=llmmodelAzure[\"api_key\"],\n",
    "                timeout=120,max_retries=3,top_p=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f7c744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnaengine = QnAEngine(embedding,llm)\n",
    "extractor = Extractor() # Markdown doc extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e67876-c437-41ad-992b-4ce540022087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ollama model\n",
    "# llmmodelOllama = { \"model\": \"gemma3:27b\",\n",
    "#                 \"url\":os.environ.get('OLLAMA_ENDPOINT',''),\n",
    "#                 \"context_window\":\"128000\"}\n",
    "\n",
    "#from llama_index.llms.ollama import Ollama\n",
    "#llm = Ollama(base_url=llmmodelOllama[\"url\"],\n",
    "#             model=llmmodelOllama[\"model\"], \n",
    "#             context_window=int(llmmodelOllama[\"context_window\"]),\n",
    "#            request_timeout=300.0,\n",
    "#            temperature=0.0,\n",
    "#            additional_kwargs={\"seed\":1337})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f0daa1-7706-4651-b713-78ac66c5533a",
   "metadata": {},
   "source": [
    "**PROCUREMENT FILE SETTINGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88446367-533a-4e00-b3ff-239802a86698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions loaded\n"
     ]
    }
   ],
   "source": [
    "# Script dir for getting relative paths for notebook file\n",
    "script_dir = globals()['_dh'][0] \n",
    "\n",
    "# Document paths\n",
    "question_file_path = script_dir / \"questions\" / \"questions.yaml\"\n",
    "prompt_file = script_dir / \"questions\" / \"prompts.tsv\"\n",
    "report_dir = script_dir / \"reports\"\n",
    "config_dir = script_dir / \"config\"\n",
    "procurement_file_dir = script_dir / \"cfla_files\"\n",
    "answer_file_dir = script_dir / \"answers\"\n",
    "\n",
    "# Loading static information TODO\n",
    "question_dictionary = get_questions(question_file_path)\n",
    "promptdict = get_prompt_dict(prompt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78357252",
   "metadata": {},
   "source": [
    "**MAIN Q/A GENERATION SCRIPT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5149a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 config files in c:\\Users\\endij\\OneDrive\\Dokumenti\\Justine\\vpp-cfla\\config\n",
      "Processing config file: c:\\Users\\endij\\OneDrive\\Dokumenti\\Justine\\vpp-cfla\\config\\KND-2020_20.ini\n",
      "An exception occurred: FileNotFoundError 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: |           [ time left: ? ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 segments created and vectorized.\n",
      "Index is ready.\n",
      "1 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An exception in askQuestion: IndexError tuple index out of range\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\endij\\OneDrive\\Dokumenti\\Justine\\vpp-cfla\\scripts\\vectorindex.py:335\u001b[0m, in \u001b[0;36mQnAEngine.getSimilarNodes\u001b[1;34m(self, q, n, prevnext)\u001b[0m\n\u001b[0;32m    334\u001b[0m retriever \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnewindex\u001b[38;5;241m.\u001b[39mas_retriever(similarity_top_k\u001b[38;5;241m=\u001b[39mn)   \n\u001b[1;32m--> 335\u001b[0m retrieved_nodes \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;66;03m#result = []\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\endij\\OneDrive\\Dokumenti\\Justine\\vpp-cfla\\venv\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:261\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 261\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\endij\\OneDrive\\Dokumenti\\Justine\\vpp-cfla\\venv\\lib\\site-packages\\llama_index\\core\\base\\base_retriever.py:245\u001b[0m, in \u001b[0;36mBaseRetriever.retrieve\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    242\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mRETRIEVE,\n\u001b[0;32m    243\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mQUERY_STR: query_bundle\u001b[38;5;241m.\u001b[39mquery_str},\n\u001b[0;32m    244\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m retrieve_event:\n\u001b[1;32m--> 245\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m     nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_recursive_retrieval(query_bundle, nodes)\n",
      "File \u001b[1;32mc:\\Users\\endij\\OneDrive\\Dokumenti\\Justine\\vpp-cfla\\venv\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:261\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 261\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\endij\\OneDrive\\Dokumenti\\Justine\\vpp-cfla\\venv\\lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\retriever.py:101\u001b[0m, in \u001b[0;36mVectorIndexRetriever._retrieve\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m     96\u001b[0m         query_bundle\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     97\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embed_model\u001b[38;5;241m.\u001b[39mget_agg_embedding_from_queries(\n\u001b[0;32m     98\u001b[0m                 query_bundle\u001b[38;5;241m.\u001b[39membedding_strs\n\u001b[0;32m     99\u001b[0m             )\n\u001b[0;32m    100\u001b[0m         )\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_nodes_with_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\endij\\OneDrive\\Dokumenti\\Justine\\vpp-cfla\\venv\\lib\\site-packages\\llama_index\\core\\indices\\vector_store\\retrievers\\retriever.py:177\u001b[0m, in \u001b[0;36mVectorIndexRetriever._get_nodes_with_embeddings\u001b[1;34m(self, query_bundle_with_embeddings)\u001b[0m\n\u001b[0;32m    176\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_vector_store_query(query_bundle_with_embeddings)\n\u001b[1;32m--> 177\u001b[0m query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vector_store\u001b[38;5;241m.\u001b[39mquery(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_kwargs)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_node_list_from_query_result(query_result)\n",
      "File \u001b[1;32mc:\\Users\\endij\\OneDrive\\Dokumenti\\Justine\\vpp-cfla\\venv\\lib\\site-packages\\llama_index\\vector_stores\\faiss\\base.py:195\u001b[0m, in \u001b[0;36mFaissVectorStore.query\u001b[1;34m(self, query, **kwargs)\u001b[0m\n\u001b[0;32m    194\u001b[0m query_embedding_np \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(query_embedding, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)[np\u001b[38;5;241m.\u001b[39mnewaxis, :]\n\u001b[1;32m--> 195\u001b[0m dists, indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_faiss_index\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_embedding_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_top_k\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    198\u001b[0m dists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(dists[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\endij\\OneDrive\\Dokumenti\\Justine\\vpp-cfla\\venv\\lib\\site-packages\\faiss\\class_wrappers.py:331\u001b[0m, in \u001b[0;36mhandle_Index.<locals>.replacement_search\u001b[1;34m(self, x, k, params, D, I)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m k \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m D \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mAssertionError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 25\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m qnaengine\u001b[38;5;241m.\u001b[39mcreateIndex(\n\u001b[0;32m     18\u001b[0m         procurement_content,\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcurement\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     20\u001b[0m         chunk_size\u001b[38;5;241m=\u001b[39membedding_conf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_size\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     21\u001b[0m         chunk_overlap\u001b[38;5;241m=\u001b[39membedding_conf[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_overlap\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     22\u001b[0m         )\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Generating results\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m results_table \u001b[38;5;241m=\u001b[39m gen_results(qnaengine, configfile, embedding_conf, question_dictionary, answer_dictionary, promptdict)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Save output\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# TODO probably should merge the output file together; One output file for the entire run, that contains each specific procurement results\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# TODO maybe implement some crash prevention strategy, so if some file breaks it doesn't break the entire run\u001b[39;00m\n\u001b[0;32m     31\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(results_table, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAtbilde\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSagaidāmā atbilde\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPamatojums\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\endij\\OneDrive\\Dokumenti\\Justine\\vpp-cfla\\scripts\\gen_results.py:55\u001b[0m, in \u001b[0;36mgen_results\u001b[1;34m(qnaengine, configfile, embedding_conf, question_dictonary, answer_dictonary, promptdict)\u001b[0m\n\u001b[0;32m     48\u001b[0m     results_table\u001b[38;5;241m.\u001b[39mappend(ask_question_save_answer(qnaengine, \n\u001b[0;32m     49\u001b[0m                                                   embedding_conf,\n\u001b[0;32m     50\u001b[0m                                                   promptdict[\u001b[38;5;28mstr\u001b[39m(singleq[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnr\u001b[39m\u001b[38;5;124m'\u001b[39m])] \u001b[38;5;241m+\u001b[39m extrainfo, \n\u001b[0;32m     51\u001b[0m                                                   singleq[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m     52\u001b[0m                                                   \u001b[38;5;28mstr\u001b[39m(singleq[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnr\u001b[39m\u001b[38;5;124m'\u001b[39m]), \n\u001b[0;32m     53\u001b[0m                                                   singlea[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m results_table[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m results_table[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m2\u001b[39m]: \u001b[38;5;66;03m# TODO make this more readable; this check is in multiple ifs\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m         nodes \u001b[38;5;241m=\u001b[39m \u001b[43mqnaengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetSimilarNodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingleq\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43membedding_conf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_similar\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQ: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msingleq[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnodes[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,file\u001b[38;5;241m=\u001b[39mofile) \n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestions\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m singleq:\n",
      "File \u001b[1;32mc:\\Users\\endij\\OneDrive\\Dokumenti\\Justine\\vpp-cfla\\scripts\\vectorindex.py:374\u001b[0m, in \u001b[0;36mQnAEngine.getSimilarNodes\u001b[1;34m(self, q, n, prevnext)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m:texts, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m:scores, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m:metadata})\n\u001b[0;32m    373\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m--> 374\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn exception occurred: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(error)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43merror\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# TODO config file loop; For each config in config_folder_path; # TODO add parallel prompting\n",
    "# Create an array of ini files and then call them in a loop; This will give us more control over which files to call/exclude\n",
    "\n",
    "ini_files = [f for f in os.listdir(config_dir) if f.endswith('.ini')]\n",
    "print(f\"Found {len(ini_files)} config files in {config_dir}\")\n",
    "\n",
    "\n",
    "for file in ini_files:\n",
    "        configfile = config_dir / file\n",
    "        print(f\"Processing config file: {configfile}\")\n",
    "        procurement_id, procurement_file, agreement_file, answer_file = get_config_data(configfile, procurement_file_dir, answer_file_dir)\n",
    "        answer_dictionary = get_answers(answer_file)\n",
    "\n",
    "        # Getting markdown text from procurement doc\n",
    "        procurement_content = get_procurement_content(extractor, procurement_file, agreement_file)\n",
    "\n",
    "        # Creating FAISS vector index for the procurement document\n",
    "        await qnaengine.createIndex(\n",
    "                procurement_content,\n",
    "                \"Procurement\",\n",
    "                chunk_size=embedding_conf[\"chunk_size\"],\n",
    "                chunk_overlap=embedding_conf[\"chunk_overlap\"]\n",
    "                )\n",
    "\n",
    "        # Generating results\n",
    "        results_table = gen_results(qnaengine, configfile, embedding_conf, question_dictionary, answer_dictionary, promptdict)\n",
    "\n",
    "        # Save output\n",
    "\n",
    "        # TODO probably should merge the output file together; One output file for the entire run, that contains each specific procurement results\n",
    "        # TODO maybe implement some crash prevention strategy, so if some file breaks it doesn't break the entire run\n",
    "        data = pd.DataFrame(results_table, columns=[\"Nr\", \"Atbilde\", \"Sagaidāmā atbilde\", \"Pamatojums\"])\n",
    "        precision = (data['Atbilde'] == data['Sagaidāmā atbilde']).sum()/len(data)\n",
    "        print(f\"PRECIZITĀTE: {precision*100}%\")\n",
    "\n",
    "        # Save final output file\n",
    "        with open(f\"{report_dir}\\{date.today():%d.%m}_{procurement_id.replace('/','_')}.htm\", 'w', encoding='utf-8') as ofile:\n",
    "                print(data.to_html(index=False).replace('\\\\n','<br>'),file=ofile)\n",
    "                print(f\"PRECIZITĀTE: {precision*100}%\",file=ofile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
