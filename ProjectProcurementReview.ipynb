{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4329b8b7-d7a7-449b-81b7-af351449627b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import configparser\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f04cb-807c-48b2-b474-8b97dbb0a6d5",
   "metadata": {},
   "source": [
    "**CURRENT SETTINGS: Embedding and language models, Chunk size, etc.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a282ce0b-1aba-417c-bf9a-15cbe840c485",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddingmodel = \"BAAI/bge-m3\"\n",
    "#embeddingmodel = \"nomic-ai/nomic-embed-text-v2-moe\"\n",
    "#embeddingmodel = \"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3e114f1-c05e-48b1-b56a-051ece6102eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Azure model\n",
    "llmmodelAzure = { \"model\": \"gpt-4o\",\n",
    "                \"version\":os.environ.get('AZURE_OPENAI_VERSION','2024-08-01-preview'),\n",
    "                \"azure_deployment\":\"gpt-4o\",\n",
    "                \"azure_endpoint\":os.environ.get('AZURE_ENDPOINT',''),\n",
    "                \"api_key\":os.environ.get('AZURE_OPENAI_KEY','')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e67876-c437-41ad-992b-4ce540022087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemma3:27b', 'url': 'http://192.168.2.128:11434', 'context_window': '128000'}\n"
     ]
    }
   ],
   "source": [
    "#Ollama model\n",
    "llmmodelOllama = { \"model\": \"gemma3:27b\",\n",
    "                \"url\":os.environ.get('OLLAMA_ENDPOINT',''),\n",
    "                \"context_window\":\"128000\"}\n",
    "print(llmmodelOllama)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04bb3749-308d-466a-badf-952e8d2c6794",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_file_path = \"C:\\\\Repos\\\\vpp-cfla\\\\questions\\\\questions.yaml\"\n",
    "prompt_file = 'C:\\\\Repos\\\\vpp-cfla\\\\questions\\\\prompts.tsv'\n",
    "report_dir = 'C:\\\\Repos\\\\vpp-cfla\\\\reports'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f0daa1-7706-4651-b713-78ac66c5533a",
   "metadata": {},
   "source": [
    "**PROCUREMENT SETTINGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88446367-533a-4e00-b3ff-239802a86698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configfile = 'C:\\\\Repos\\\\vpp-cfla\\\\config\\\\SNP-2021_07_AK.ini'\n",
    "#configfile = 'C:\\\\Repos\\\\vpp-cfla\\\\config\\\\KND-2020_07.ini'\n",
    "configfile = 'C:\\\\Repos\\\\vpp-cfla\\\\config\\\\KND-2020_20.ini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5a22f74-1564-4398-9f81-1c8a6781622b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Repos\\\\vpp-cfla\\\\config\\\\KND-2020_20.ini']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(configfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae402ad5-0c4e-4f46-87d7-ef6c9e9eea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "EIS_URL = config.get('Procurement', 'EIS_URL')\n",
    "procurement_id = config.get('Procurement', 'procurement_id')\n",
    "procurement_file = config.get('Procurement', 'procurement_file')\n",
    "answer_file = config.get('Procurement', 'answer_file')\n",
    "if 'agreement_file' in config['Procurement']:\n",
    "    agreement_file = config.get('Procurement', 'agreement_file')\n",
    "else:\n",
    "    agreement_file = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f75d98e-b331-4673-8223-2911b626c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1536\n",
    "chunk_overlap = 0\n",
    "top_similar = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7886b186-5505-4211-8345-731d210f55e8",
   "metadata": {},
   "source": [
    "**STEP 1: Getting markdown text from the _Project Procurement document_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "329be7b5-191b-4573-bcb6-3560d0897086",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.extractmd import Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5d30e80-c648-4214-95b8-a989eb5c31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = Extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "582d1e81-c3e4-4288-a6de-d5607cc782a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "procurement_content = ex.convert2markdown(procurement_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16ad1317-a592-47c6-9755-991b575757db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(agreement_file) > 0:\n",
    "    agreement_content = ex.convert2markdown(agreement_file)\n",
    "    procurement_content = procurement_content + \"\\n\\n# IEPIRKUMA LĪGUMA PROJEKTS\\n\\n\" + agreement_content\n",
    "    with open(\"tmp3.md\", 'w', encoding='utf-8') as fout:\n",
    "        print(procurement_content,file=fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f2893b-e2d3-456e-84ce-a36f337088e9",
   "metadata": {},
   "source": [
    "**STEP 2: Initializing embedding and llm object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2e3431f-33af-42c6-8fc4-dcadaf6c5951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Daiga.Deksne\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab7d3a84-33a6-4d39-8552-10f28abdc308",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=HuggingFaceEmbedding(model_name=embeddingmodel,trust_remote_code=True)\n",
    "\n",
    "#For nomic-embed-text-v2-moe\n",
    "#embedding=HuggingFaceEmbedding(model_name=embeddingmodel,trust_remote_code=True,query_instruction=\"search_query: \",text_instruction=\"search_document: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96cf2024-f901-4f19-b21c-23f42d75d4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n"
     ]
    }
   ],
   "source": [
    "print(len(embedding._get_text_embedding(\"Test string\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26be590e-9e1b-4414-9743-f99dc2587ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "llm = Ollama(base_url=llmmodelOllama[\"url\"],\n",
    "             model=llmmodelOllama[\"model\"], \n",
    "             context_window=int(llmmodelOllama[\"context_window\"]),\n",
    "            request_timeout=300.0,\n",
    "            temperature=0.0,\n",
    "            additional_kwargs={\"seed\":1337})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b5b1c8d-eb6f-48c1-8ce3-cc883946043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from llama_index.llms.azure_openai import AzureOpenAI\n",
    "#llm=AzureOpenAI(azure_deployment=llmmodelAzure[\"azure_deployment\"],\n",
    "#                azure_endpoint=llmmodelAzure[\"azure_endpoint\"],temperature=0.0,\n",
    "#                api_version=llmmodelAzure[\"version\"], api_key=llmmodelAzure[\"api_key\"],\n",
    "#                timeout=120,max_retries=3,top_p=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5be0a06e-6884-4bb1-b5fc-6d18855b8098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128000\n"
     ]
    }
   ],
   "source": [
    "#LLM test\n",
    "#response = llm.complete(\"What day is today?\")\n",
    "#response\n",
    "print(llm.metadata.context_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8dd10c-2ab5-4eca-baa9-e3091bf62ee4",
   "metadata": {},
   "source": [
    "**STEP 3: Creating FAISS vector index for the procurement document**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df767f7e-4b06-4d54-92e0-48eb45e1ec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.vectorindex import QnAEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3316131-4b65-4b4c-8d64-643c3c1553d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnaengine = QnAEngine(embedding,llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "168da01c-6f5d-42a0-898f-4ca7cfd05e4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████████████████████████████████████████████████████████████████ [ time left: 00:00 ]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 segments created and vectorized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ret = await qnaengine.createIndex(procurement_content,\"Procurement\",chunk_size=chunk_size,chunk_overlap=chunk_overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b501f2b7-428f-4553-be6b-0c7268a2b788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index is ready.\n"
     ]
    }
   ],
   "source": [
    "if ret == False:\n",
    "    print(\"**Failed to create index!**\")\n",
    "    exit\n",
    "else:\n",
    "    print(\"Index is ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b115a12-b748-4262-84ed-6967502f55ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieval test\n",
    "#similarsegments = qnaengine.getSimilarNodes(\"Vai iepirkums ir sadalīts daļās?\")\n",
    "#print(similarsegments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "498b44df-d770-4078-961b-44eec6935051",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generation test\n",
    "#result = qnaengine.askQuestion(\"Noskaidro, vai lietotāja apgalvojums ir patiess? Domā soli pa soli, katram solim neveltot vairāk par pieciem vārdiem. Pamato savu atbildi, citējot fragmentu no konteksta. Atbildei jābūt 'jā', 'nē' vai 'kontekstā nav informācijas'. Atbildi ietver kvadrātiekavās '[]'. Ja kontekstā nav informācijas, paskaidro, kāda informācija ir nepieciešama, lai novērtētu apgalvojumu.\",\n",
    "#                              \"Pasūtītājs ir nodrošinājis iespēju piegādātājiem iepazīties uz vietas ar iepirkuma papildu dokumentiem, kam tehnisku iemeslu dēļ vai tajos iekļautās informācijas vai komerciālu interešu aizsardzības dēļ nav nodrošināma brīva un tieša elektroniska piekļuve, sākot ar attiecīgā iepirkuma izsludināšanas brīdi\",\n",
    "#                              usecontext=True)\n",
    "#result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af21118d-8a9e-4c3d-9da7-0a4ff7888fbd",
   "metadata": {},
   "source": [
    "#### **STEP 4: Acquiring supplementary information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8d3e9ffa-c441-4296-8d92-8f189f460284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utilities import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "954d1600-2019-42c2-9c6d-93353a033621",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PIL.txt','r',encoding='utf-8') as file:\n",
    "    piltxt = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "105c0075-cb63-4c3b-99c4-71e2d278bfc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pattern = r'^(?P<key>(\\d+\\.\\s+(pants|pielikums))|Pārejas noteikumi)'\n",
    "pilchapters = extract_chapters(piltxt, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "839ccfac-c11f-45fd-8a80-062cc5842bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MK107.md','r',encoding='utf-8') as file:\n",
    "    mk107txt = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e71b270-e3ec-422a-835c-baa40792dc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'^(?P<key>[# ]*\\d+)\\.\\s+'\n",
    "mk107chapters = extract_chapters(mk107txt, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca6d35dc-322f-4d21-8267-c8da69130bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('S_LR_NSL.txt','r',encoding='utf-8') as file:\n",
    "    nsltxt = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2f4f5321-cee7-4032-9488-b82e83a4d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'^(?P<key>(\\d+\\.(\\d+)?\\s+pants))'\n",
    "nslchapters = extract_chapters(nsltxt, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c925bb17-2b33-4201-8838-f95c9dc093fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MK_I3.txt','r',encoding='utf-8') as file:\n",
    "    mki3txt = file.read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edb4aa65-c84e-4a7b-a030-79fbf2449b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'^\\*\\* (?P<key>\\d+(\\.\\d+)?)\\.\\s+'\n",
    "mki3chapters = extract_chapters(mki3txt, pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a235a0b5-29dd-4b85-8574-b95c81dee4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eiscontent = await text_from_url(EIS_URL)\n",
    "#print(eiscontent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5c25467e-ca18-425f-97d4-7cec4f4fd4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "promptdict = {}\n",
    "\n",
    "with open(prompt_file,'r',encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        lineparts = line.strip().split('\\t')\n",
    "        if len(lineparts)==2:\n",
    "            for q in lineparts[1].split(','):\n",
    "                promptdict[str(q)] = lineparts[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a44a255-dbc6-476f-bc13-c6c78518cb62",
   "metadata": {},
   "source": [
    "##### **STEP 5: Processing questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a995cf6-c30d-4f9a-b403-aa766927ed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6085b510-1fdb-4bd9-bd5c-aad73f771fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(question_file_path, 'r', encoding='utf-8') as file:\n",
    "        question_dictonary = yaml.load(file, Loader=yaml.BaseLoader)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{question_file_path}' not found.\")\n",
    "    exit\n",
    "except yaml.YAMLError as e:\n",
    "    print(f\"Error parsing YAML file: {e}\")\n",
    "    exit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "64b39e49-ce83-47f8-8eac-95d2ede03620",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(answer_file, 'r', encoding='utf-8') as file:\n",
    "        answer_dictonary = yaml.load(file, Loader=yaml.BaseLoader)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File '{answer_file}' not found.\")\n",
    "    exit\n",
    "except yaml.YAMLError as e:\n",
    "    print(f\"Error parsing YAML file: {e}\")\n",
    "    exit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78e76343-d55d-4383-a217-447856b58df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "db61605c-c57f-4017-b8ad-50527ed4b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def askQuestionSaveAnswer(prompt, question, nr, expectedanswer=''):\n",
    "    result = qnaengine.askQuestion(prompt, question, usecontext=True,n=top_similar)\n",
    "    result = re.sub(r'\\n\\n+',r'\\n',result).strip()\n",
    "\n",
    "    answer = re.search(r'\\{[^\\{\\}]+\\}',result, re.IGNORECASE)\n",
    "    if answer:\n",
    "        try:\n",
    "            jsonanswer=json.loads(answer.group(1))\n",
    "            llmanswer = jsonanswer.get('answer','')\n",
    "            record = [nr, llmanswer, expectedanswer, result]\n",
    "            return record\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    answer = re.search(r'\\[\\**(jā|nē|kontekstā nav informācijas|n/a)\\**\\]',result, re.IGNORECASE)\n",
    "    \n",
    "    if answer:\n",
    "        llmanswer=answer.group(1)\n",
    "        #result = result.replace(f\"[{llmanswer}]\",\"\").replace(f\"Atbilde:\",\"\")\n",
    "        record = [nr, llmanswer, expectedanswer, result]\n",
    "    else:\n",
    "        answer = re.search(r\"'?(jā|nē|kontekstā nav informācijas|n/a)'?\", result, re.IGNORECASE)\n",
    "        if not answer:\n",
    "            answer = re.search(r'\\[(ja|ne)\\]', result, re.IGNORECASE)\n",
    "        if answer:\n",
    "            record = [nr, answer.group(1).lower(), expectedanswer, result]\n",
    "        else:\n",
    "            record = [nr, '', expectedanswer, result] \n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3af6c11f-beb5-4544-8006-ba89afb39e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for singleq in question_dictonary:\n",
    "#    extrainfo = get_extra_info(singleq, pilchapters, mk107chapters)    \n",
    "#    if len(extrainfo) > 0:\n",
    "#        print(singleq)\n",
    "#        print(extrainfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a9764b18-7d2e-4165-8b8b-6d1642cbaea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 35.1 35.2 35.3 35.4 35.5 35.6 35.7 35.8 36 37 37.1 37.2 37.3 37.4 37.5 37.6 37.7 37.8 37.9 37.10 37.11 37.12 37.13 38 38.1 38.2 38.3 38.4 38.5 38.6 38.7 38.8 38.9 39 39.1 39.2 39.3 39.4 39.5 39.6 39.7 39.8 39.9 39.10 39.11 39.12 39.13 39.14 39.15 39.16 39.17 39.18 39.19 39.20 39.21 39.22 39.23 39.24 39.25 39.26 39.27 39.28 39.29 39.30 39.31 39.32 39.33 39.34 39.35 39.36 39.37 39.38 39.39 39.40 40 40.1 40.2 40.3 40.4 40.5 40.6 40.7 40.8 40.9 40.10 40.11 40.12 41 42 43 44 45 46 47 48 49 50 51 51.1 51.2 51.3 51.4 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 "
     ]
    }
   ],
   "source": [
    "with open(\"nodes.log\", 'a', encoding='utf-8') as ofile:\n",
    "    print(f\"\\n*********************\\n{configfile}, {configfile}\\n{embeddingmodel}, top_similar: {top_similar}, chunk-size: {chunk_size}, chunk_overlap: {chunk_overlap}\",file=ofile)\n",
    "    for singleq, singlea in zip(question_dictonary,answer_dictonary):\n",
    "        print(singleq['nr'],end=' ')\n",
    "        bcontinue = True\n",
    "        extrainfo = get_extra_info(singleq, pilchapters, mk107chapters, nslchapters, mki3chapters)    \n",
    "        extrainfo = qnaengine.compressPrompt(extrainfo,3000)\n",
    "        \n",
    "        if 'question0' in singleq:\n",
    "            result0 = askQuestionSaveAnswer(promptdict['0'] + extrainfo, singleq['question0'], f\"{singleq['nr']}-0\", singlea['answer0'])\n",
    "            table.append(result0)\n",
    "            if table[-1][1] != table[-1][2]:\n",
    "                nodes = qnaengine.getSimilarNodes(singleq['question0'])\n",
    "                print(f\"\\nQ: {singleq['nr']}-0\\n{nodes['text']}\\n{nodes['metadata']}\\n{nodes['score']}\",file=ofile) \n",
    "    \n",
    "            if result0[1] == 'nē':\n",
    "                bcontinue = False\n",
    "        \n",
    "        if bcontinue == False:\n",
    "            if 'question' in singleq:\n",
    "                table.append([str(singleq['nr']),'n/a',singlea['answer'],''])\n",
    "            elif 'questions' in singleq:\n",
    "                for listq, lista in zip(singleq['questions'],singlea['answers']):\n",
    "                    table.append([str(listq['nr']),'n/a',lista['answer'],''])\n",
    "        elif 'question' in singleq:\n",
    "            table.append(askQuestionSaveAnswer(promptdict[str(singleq['nr'])] + extrainfo, singleq['question'], str(singleq['nr']), singlea['answer']))\n",
    "            if table[-1][1] != table[-1][2]: \n",
    "                nodes = qnaengine.getSimilarNodes(singleq['question'])\n",
    "                print(f\"\\nQ: {singleq['nr']}\\n{nodes['text']}\\n{nodes['metadata']}\\n{nodes['score']}\",file=ofile) \n",
    "        elif 'questions' in singleq:\n",
    "            for listq, lista in zip(singleq['questions'],singlea['answers']):\n",
    "                print(listq['nr'],end=' ')\n",
    "                bcontinue = True\n",
    "                extrainfo = get_extra_info(listq, pilchapters, mk107chapters, nslchapters, mki3chapters) \n",
    "                extrainfo = qnaengine.compressPrompt(extrainfo,3000)\n",
    "                \n",
    "                if 'question0' in listq:\n",
    "                    result0 = askQuestionSaveAnswer(promptdict['0'] + extrainfo, listq['question0'], f\"{listq['nr']}-0\", lista['answer0'])\n",
    "                    table.append(result0)\n",
    "                    if table[-1][1] != table[-1][2]:\n",
    "                        nodes = qnaengine.getSimilarNodes(listq['question0'])\n",
    "                        print(f\"\\nQ: {listq['nr']}-0\\n{nodes['text']}\\n{nodes['metadata']}\\n{nodes['score']}\",file=ofile) \n",
    "            \n",
    "                    if result0[1] == 'nē':\n",
    "                        bcontinue = False\n",
    "                        \n",
    "                if bcontinue == False:\n",
    "                    table.append([str(listq['nr']),'n/a',lista['answer0'],''])\n",
    "                else:\n",
    "                    table.append(askQuestionSaveAnswer(promptdict[str(listq['nr'])] + extrainfo, listq['question'], str(listq['nr']), lista['answer']))\n",
    "                    if table[-1][1] != table[-1][2]:\n",
    "                        nodes = qnaengine.getSimilarNodes(listq['question'])\n",
    "                        print(f\"\\nQ: {listq['nr']}\\n{nodes['text']}\\n{nodes['metadata']}\\n{nodes['score']}\",file=ofile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dec02eda-ab8e-4ffe-880a-73cffbb8a801",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for item in table:\n",
    "#    print(f\"--------------------------------------------------\")\n",
    "#    print(f\"NR: {item[0]}\\nLLM: {item[1]} | HUMAN: {item[2]}\\nFULL LLM ANSWER:\\n{item[3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "944bb3f4-447a-4ff3-8537-35831dc3c735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECIZITĀTE: 50.73170731707317%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(table, columns=[\"Nr\", \"Atbilde\", \"Sagaidāmā atbilde\", \"Pamatojums\"])\n",
    "precision = (data['Atbilde'] == data['Sagaidāmā atbilde']).sum()/len(data)\n",
    "print(f\"PRECIZITĀTE: {precision*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e9423524-0a87-4d76-8948-48ab7a40d672",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{report_dir}\\{date.today():%d.%m}_{procurement_id.replace('/','_')}.htm\", 'w', encoding='utf-8') as ofile:\n",
    "    print(data.to_html(index=False).replace('\\\\n','<br>'),file=ofile)\n",
    "    print(f\"PRECIZITĀTE: {precision*100}%\",file=ofile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb9c79a-7160-456e-8cc8-f80058e31abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ad4e5a-380d-471a-8aa5-e6e1d7c493db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
